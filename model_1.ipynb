{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install joblib. This will be used to save your model. \n",
    "# Restart your kernel after installing \n",
    "# !pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>koi_time0bk_err2</th>\n",
       "      <th>koi_impact</th>\n",
       "      <th>koi_impact_err1</th>\n",
       "      <th>koi_impact_err2</th>\n",
       "      <th>koi_duration</th>\n",
       "      <th>koi_duration_err1</th>\n",
       "      <th>koi_duration_err2</th>\n",
       "      <th>koi_depth</th>\n",
       "      <th>koi_depth_err1</th>\n",
       "      <th>koi_depth_err2</th>\n",
       "      <th>koi_prad</th>\n",
       "      <th>koi_prad_err1</th>\n",
       "      <th>koi_prad_err2</th>\n",
       "      <th>koi_teq</th>\n",
       "      <th>koi_insol</th>\n",
       "      <th>koi_insol_err1</th>\n",
       "      <th>koi_insol_err2</th>\n",
       "      <th>koi_model_snr</th>\n",
       "      <th>koi_tce_plnt_num</th>\n",
       "      <th>koi_steff</th>\n",
       "      <th>koi_steff_err1</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.418383</td>\n",
       "      <td>2.479000e-04</td>\n",
       "      <td>-2.479000e-04</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>-0.003520</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.059</td>\n",
       "      <td>-0.443</td>\n",
       "      <td>4.50700</td>\n",
       "      <td>0.11600</td>\n",
       "      <td>-0.11600</td>\n",
       "      <td>874.8</td>\n",
       "      <td>35.5</td>\n",
       "      <td>-35.5</td>\n",
       "      <td>2.83</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>443</td>\n",
       "      <td>9.11</td>\n",
       "      <td>2.87</td>\n",
       "      <td>-1.62</td>\n",
       "      <td>25.8</td>\n",
       "      <td>2</td>\n",
       "      <td>5455</td>\n",
       "      <td>81</td>\n",
       "      <td>-81</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.899140</td>\n",
       "      <td>1.490000e-05</td>\n",
       "      <td>-1.490000e-05</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>-0.000581</td>\n",
       "      <td>0.969</td>\n",
       "      <td>5.126</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>1.78220</td>\n",
       "      <td>0.03410</td>\n",
       "      <td>-0.03410</td>\n",
       "      <td>10829.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>14.60</td>\n",
       "      <td>3.92</td>\n",
       "      <td>-1.31</td>\n",
       "      <td>638</td>\n",
       "      <td>39.30</td>\n",
       "      <td>31.04</td>\n",
       "      <td>-10.49</td>\n",
       "      <td>76.3</td>\n",
       "      <td>1</td>\n",
       "      <td>5853</td>\n",
       "      <td>158</td>\n",
       "      <td>-176</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>2.630000e-07</td>\n",
       "      <td>-2.630000e-07</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>1.276</td>\n",
       "      <td>0.115</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>2.40641</td>\n",
       "      <td>0.00537</td>\n",
       "      <td>-0.00537</td>\n",
       "      <td>8079.2</td>\n",
       "      <td>12.8</td>\n",
       "      <td>-12.8</td>\n",
       "      <td>33.46</td>\n",
       "      <td>8.50</td>\n",
       "      <td>-2.83</td>\n",
       "      <td>1395</td>\n",
       "      <td>891.96</td>\n",
       "      <td>668.95</td>\n",
       "      <td>-230.35</td>\n",
       "      <td>505.6</td>\n",
       "      <td>1</td>\n",
       "      <td>5805</td>\n",
       "      <td>157</td>\n",
       "      <td>-174</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.525592</td>\n",
       "      <td>3.760000e-06</td>\n",
       "      <td>-3.760000e-06</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>-0.001130</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.235</td>\n",
       "      <td>-0.478</td>\n",
       "      <td>1.65450</td>\n",
       "      <td>0.04200</td>\n",
       "      <td>-0.04200</td>\n",
       "      <td>603.3</td>\n",
       "      <td>16.9</td>\n",
       "      <td>-16.9</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.88</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>1406</td>\n",
       "      <td>926.16</td>\n",
       "      <td>874.33</td>\n",
       "      <td>-314.24</td>\n",
       "      <td>40.9</td>\n",
       "      <td>1</td>\n",
       "      <td>6031</td>\n",
       "      <td>169</td>\n",
       "      <td>-211</td>\n",
       "      <td>4.438</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>1.046</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.134435</td>\n",
       "      <td>1.050000e-05</td>\n",
       "      <td>-1.050000e-05</td>\n",
       "      <td>172.979370</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>-0.001900</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.139</td>\n",
       "      <td>-0.532</td>\n",
       "      <td>3.14020</td>\n",
       "      <td>0.06730</td>\n",
       "      <td>-0.06730</td>\n",
       "      <td>686.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>-18.7</td>\n",
       "      <td>2.77</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>1160</td>\n",
       "      <td>427.65</td>\n",
       "      <td>420.33</td>\n",
       "      <td>-136.70</td>\n",
       "      <td>40.2</td>\n",
       "      <td>2</td>\n",
       "      <td>6046</td>\n",
       "      <td>189</td>\n",
       "      <td>-232</td>\n",
       "      <td>4.486</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>296.28613</td>\n",
       "      <td>48.224670</td>\n",
       "      <td>15.714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  koi_disposition  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  \\\n",
       "0       CONFIRMED              0              0              0              0   \n",
       "1  FALSE POSITIVE              0              1              0              0   \n",
       "2  FALSE POSITIVE              0              1              0              0   \n",
       "3       CONFIRMED              0              0              0              0   \n",
       "4       CONFIRMED              0              0              0              0   \n",
       "\n",
       "   koi_period  koi_period_err1  koi_period_err2  koi_time0bk  \\\n",
       "0   54.418383     2.479000e-04    -2.479000e-04   162.513840   \n",
       "1   19.899140     1.490000e-05    -1.490000e-05   175.850252   \n",
       "2    1.736952     2.630000e-07    -2.630000e-07   170.307565   \n",
       "3    2.525592     3.760000e-06    -3.760000e-06   171.595550   \n",
       "4    4.134435     1.050000e-05    -1.050000e-05   172.979370   \n",
       "\n",
       "   koi_time0bk_err1  koi_time0bk_err2  koi_impact  koi_impact_err1  \\\n",
       "0          0.003520         -0.003520       0.586            0.059   \n",
       "1          0.000581         -0.000581       0.969            5.126   \n",
       "2          0.000115         -0.000115       1.276            0.115   \n",
       "3          0.001130         -0.001130       0.701            0.235   \n",
       "4          0.001900         -0.001900       0.762            0.139   \n",
       "\n",
       "   koi_impact_err2  koi_duration  koi_duration_err1  koi_duration_err2  \\\n",
       "0           -0.443       4.50700            0.11600           -0.11600   \n",
       "1           -0.077       1.78220            0.03410           -0.03410   \n",
       "2           -0.092       2.40641            0.00537           -0.00537   \n",
       "3           -0.478       1.65450            0.04200           -0.04200   \n",
       "4           -0.532       3.14020            0.06730           -0.06730   \n",
       "\n",
       "   koi_depth  koi_depth_err1  koi_depth_err2  koi_prad  koi_prad_err1  \\\n",
       "0      874.8            35.5           -35.5      2.83           0.32   \n",
       "1    10829.0           171.0          -171.0     14.60           3.92   \n",
       "2     8079.2            12.8           -12.8     33.46           8.50   \n",
       "3      603.3            16.9           -16.9      2.75           0.88   \n",
       "4      686.0            18.7           -18.7      2.77           0.90   \n",
       "\n",
       "   koi_prad_err2  koi_teq  koi_insol  koi_insol_err1  koi_insol_err2  \\\n",
       "0          -0.19      443       9.11            2.87           -1.62   \n",
       "1          -1.31      638      39.30           31.04          -10.49   \n",
       "2          -2.83     1395     891.96          668.95         -230.35   \n",
       "3          -0.35     1406     926.16          874.33         -314.24   \n",
       "4          -0.30     1160     427.65          420.33         -136.70   \n",
       "\n",
       "   koi_model_snr  koi_tce_plnt_num  koi_steff  koi_steff_err1  koi_steff_err2  \\\n",
       "0           25.8                 2       5455              81             -81   \n",
       "1           76.3                 1       5853             158            -176   \n",
       "2          505.6                 1       5805             157            -174   \n",
       "3           40.9                 1       6031             169            -211   \n",
       "4           40.2                 2       6046             189            -232   \n",
       "\n",
       "   koi_slogg  koi_slogg_err1  koi_slogg_err2  koi_srad  koi_srad_err1  \\\n",
       "0      4.467           0.064          -0.096     0.927          0.105   \n",
       "1      4.544           0.044          -0.176     0.868          0.233   \n",
       "2      4.564           0.053          -0.168     0.791          0.201   \n",
       "3      4.438           0.070          -0.210     1.046          0.334   \n",
       "4      4.486           0.054          -0.229     0.972          0.315   \n",
       "\n",
       "   koi_srad_err2         ra        dec  koi_kepmag  \n",
       "0         -0.061  291.93423  48.141651      15.347  \n",
       "1         -0.078  297.00482  48.134129      15.436  \n",
       "2         -0.067  285.53461  48.285210      15.597  \n",
       "3         -0.133  288.75488  48.226200      15.509  \n",
       "4         -0.105  296.28613  48.224670      15.714  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_columns = 50\n",
    "df = pd.read_csv(\"exoplanet_data.csv\")\n",
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "# Drop the null rows\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select your features (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.10989729330096536, 'koi_fpflag_co'),\n",
       " (0.09702646927847326, 'koi_fpflag_nt'),\n",
       " (0.06239153319176748, 'koi_fpflag_ss'),\n",
       " (0.057391101803919896, 'koi_model_snr'),\n",
       " (0.053170564912502466, 'koi_prad'),\n",
       " (0.03543704884826284, 'koi_fpflag_ec'),\n",
       " (0.03423854969333677, 'koi_prad_err1'),\n",
       " (0.03197480820338188, 'koi_duration_err1'),\n",
       " (0.03140602082219253, 'koi_steff_err1'),\n",
       " (0.0308348435561837, 'koi_duration_err2'),\n",
       " (0.030414895706824967, 'koi_steff_err2'),\n",
       " (0.029131796954743126, 'koi_prad_err2'),\n",
       " (0.0242527013931243, 'koi_time0bk_err1'),\n",
       " (0.02408518291198549, 'koi_time0bk_err2'),\n",
       " (0.02384687998951167, 'koi_duration'),\n",
       " (0.021872109748913116, 'koi_depth'),\n",
       " (0.02090272691823472, 'koi_period'),\n",
       " (0.019041278549900554, 'koi_period_err1'),\n",
       " (0.018607454769650124, 'koi_impact'),\n",
       " (0.018423771003356626, 'koi_period_err2'),\n",
       " (0.016836765803012736, 'koi_insol'),\n",
       " (0.016219189708607487, 'koi_insol_err1'),\n",
       " (0.016012764046367756, 'koi_teq'),\n",
       " (0.014573280409717495, 'koi_depth_err1'),\n",
       " (0.013490707316369699, 'koi_depth_err2'),\n",
       " (0.013204930224988712, 'koi_insol_err2'),\n",
       " (0.012698137575024526, 'koi_time0bk'),\n",
       " (0.012311623504141967, 'ra'),\n",
       " (0.010933070593175085, 'dec'),\n",
       " (0.010884749113952813, 'koi_srad_err1'),\n",
       " (0.010750779493899531, 'koi_kepmag'),\n",
       " (0.010461268244188818, 'koi_impact_err1'),\n",
       " (0.009913271917172646, 'koi_impact_err2'),\n",
       " (0.00979148155035514, 'koi_slogg_err2'),\n",
       " (0.009448325545994481, 'koi_steff'),\n",
       " (0.009342247703060007, 'koi_slogg'),\n",
       " (0.008669226339602116, 'koi_srad'),\n",
       " (0.008579939311322648, 'koi_slogg_err1'),\n",
       " (0.00841368018585756, 'koi_srad_err2'),\n",
       " (0.0031175298559579174, 'koi_tce_plnt_num')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To Calculate feature importance\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "data = df.drop('koi_disposition',axis=1)\n",
    "target = df[['koi_disposition']]\n",
    "rf = rf.fit(data, np.ravel(target))\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "sorted(zip(importances, data.columns), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_model_snr</th>\n",
       "      <th>koi_prad</th>\n",
       "      <th>koi_duration_err2</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_steff_err1</th>\n",
       "      <th>koi_prad_err1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.8</td>\n",
       "      <td>2.83</td>\n",
       "      <td>-0.11600</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>76.3</td>\n",
       "      <td>14.60</td>\n",
       "      <td>-0.03410</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "      <td>3.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>505.6</td>\n",
       "      <td>33.46</td>\n",
       "      <td>-0.00537</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>8.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.9</td>\n",
       "      <td>2.75</td>\n",
       "      <td>-0.04200</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.2</td>\n",
       "      <td>2.77</td>\n",
       "      <td>-0.06730</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   koi_fpflag_co  koi_fpflag_nt  koi_fpflag_ss  koi_model_snr  koi_prad  \\\n",
       "0              0              0              0           25.8      2.83   \n",
       "1              0              0              1           76.3     14.60   \n",
       "2              0              0              1          505.6     33.46   \n",
       "3              0              0              0           40.9      2.75   \n",
       "4              0              0              0           40.2      2.77   \n",
       "\n",
       "   koi_duration_err2  koi_fpflag_ec  koi_steff_err1  koi_prad_err1  \n",
       "0           -0.11600              0              81           0.32  \n",
       "1           -0.03410              0             158           3.92  \n",
       "2           -0.00537              0             157           8.50  \n",
       "3           -0.04200              0             169           0.88  \n",
       "4           -0.06730              0             189           0.90  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set features. This will also be used as your x values.\n",
    "selected_features = df[[ 'koi_fpflag_co', 'koi_fpflag_nt', 'koi_fpflag_ss', 'koi_model_snr', 'koi_prad','koi_duration_err2',\n",
    "                        'koi_fpflag_ec', 'koi_steff_err1', 'koi_prad_err1']]\n",
    "selected_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split\n",
    "\n",
    "Use `koi_disposition` for the y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['koi_disposition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(selected_features, y, random_state = 1, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler and perform some feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5243, 9)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale your data\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "X_scaler = MinMaxScaler()\n",
    "X_scaler.fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)\n",
    "X_train_scaled.shape\n",
    "# y_train_categorical.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8256723250047683\n",
      "Testing Data Score: 0.8237986270022883\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train_scaled, y_train)\n",
    "print(f\"Training Data Score: {classifier.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CANDIDATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CANDIDATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1748 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Prediction          Actual\n",
       "0          CANDIDATE       CANDIDATE\n",
       "1     FALSE POSITIVE  FALSE POSITIVE\n",
       "2     FALSE POSITIVE  FALSE POSITIVE\n",
       "3          CANDIDATE       CANDIDATE\n",
       "4     FALSE POSITIVE  FALSE POSITIVE\n",
       "...              ...             ...\n",
       "1743       CONFIRMED       CONFIRMED\n",
       "1744  FALSE POSITIVE  FALSE POSITIVE\n",
       "1745       CONFIRMED       CONFIRMED\n",
       "1746       CONFIRMED       CONFIRMED\n",
       "1747  FALSE POSITIVE  FALSE POSITIVE\n",
       "\n",
       "[1748 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=9))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               1000      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 11,403\n",
      "Trainable params: 11,403\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5243 samples\n",
      "Epoch 1/150\n",
      "5243/5243 - 1s - loss: 0.5012 - accuracy: 0.7360\n",
      "Epoch 2/150\n",
      "5243/5243 - 0s - loss: 0.3796 - accuracy: 0.8117\n",
      "Epoch 3/150\n",
      "5243/5243 - 0s - loss: 0.3703 - accuracy: 0.8167\n",
      "Epoch 4/150\n",
      "5243/5243 - 0s - loss: 0.3685 - accuracy: 0.8184\n",
      "Epoch 5/150\n",
      "5243/5243 - 0s - loss: 0.3669 - accuracy: 0.8173\n",
      "Epoch 6/150\n",
      "5243/5243 - 0s - loss: 0.3654 - accuracy: 0.8215\n",
      "Epoch 7/150\n",
      "5243/5243 - 0s - loss: 0.3660 - accuracy: 0.8219\n",
      "Epoch 8/150\n",
      "5243/5243 - 0s - loss: 0.3645 - accuracy: 0.8198\n",
      "Epoch 9/150\n",
      "5243/5243 - 0s - loss: 0.3635 - accuracy: 0.8226\n",
      "Epoch 10/150\n",
      "5243/5243 - 0s - loss: 0.3631 - accuracy: 0.8186\n",
      "Epoch 11/150\n",
      "5243/5243 - 0s - loss: 0.3636 - accuracy: 0.8173\n",
      "Epoch 12/150\n",
      "5243/5243 - 0s - loss: 0.3611 - accuracy: 0.8219\n",
      "Epoch 13/150\n",
      "5243/5243 - 0s - loss: 0.3622 - accuracy: 0.8217\n",
      "Epoch 14/150\n",
      "5243/5243 - 0s - loss: 0.3615 - accuracy: 0.8201\n",
      "Epoch 15/150\n",
      "5243/5243 - 0s - loss: 0.3621 - accuracy: 0.8224\n",
      "Epoch 16/150\n",
      "5243/5243 - 0s - loss: 0.3622 - accuracy: 0.8156\n",
      "Epoch 17/150\n",
      "5243/5243 - 0s - loss: 0.3625 - accuracy: 0.8198\n",
      "Epoch 18/150\n",
      "5243/5243 - 0s - loss: 0.3601 - accuracy: 0.8222\n",
      "Epoch 19/150\n",
      "5243/5243 - 0s - loss: 0.3603 - accuracy: 0.8203\n",
      "Epoch 20/150\n",
      "5243/5243 - 0s - loss: 0.3620 - accuracy: 0.8213\n",
      "Epoch 21/150\n",
      "5243/5243 - 0s - loss: 0.3596 - accuracy: 0.8207\n",
      "Epoch 22/150\n",
      "5243/5243 - 0s - loss: 0.3585 - accuracy: 0.8220\n",
      "Epoch 23/150\n",
      "5243/5243 - 0s - loss: 0.3573 - accuracy: 0.8243\n",
      "Epoch 24/150\n",
      "5243/5243 - 0s - loss: 0.3596 - accuracy: 0.8179\n",
      "Epoch 25/150\n",
      "5243/5243 - 0s - loss: 0.3584 - accuracy: 0.8219\n",
      "Epoch 26/150\n",
      "5243/5243 - 0s - loss: 0.3576 - accuracy: 0.8251\n",
      "Epoch 27/150\n",
      "5243/5243 - 0s - loss: 0.3577 - accuracy: 0.8222\n",
      "Epoch 28/150\n",
      "5243/5243 - 0s - loss: 0.3565 - accuracy: 0.8255\n",
      "Epoch 29/150\n",
      "5243/5243 - 0s - loss: 0.3571 - accuracy: 0.8247\n",
      "Epoch 30/150\n",
      "5243/5243 - 0s - loss: 0.3554 - accuracy: 0.8243\n",
      "Epoch 31/150\n",
      "5243/5243 - 0s - loss: 0.3554 - accuracy: 0.8251\n",
      "Epoch 32/150\n",
      "5243/5243 - 0s - loss: 0.3546 - accuracy: 0.8264\n",
      "Epoch 33/150\n",
      "5243/5243 - 0s - loss: 0.3526 - accuracy: 0.8259\n",
      "Epoch 34/150\n",
      "5243/5243 - 0s - loss: 0.3537 - accuracy: 0.8247\n",
      "Epoch 35/150\n",
      "5243/5243 - 0s - loss: 0.3515 - accuracy: 0.8247\n",
      "Epoch 36/150\n",
      "5243/5243 - 0s - loss: 0.3534 - accuracy: 0.8255\n",
      "Epoch 37/150\n",
      "5243/5243 - 0s - loss: 0.3514 - accuracy: 0.8270\n",
      "Epoch 38/150\n",
      "5243/5243 - 0s - loss: 0.3484 - accuracy: 0.8301\n",
      "Epoch 39/150\n",
      "5243/5243 - 0s - loss: 0.3476 - accuracy: 0.8268\n",
      "Epoch 40/150\n",
      "5243/5243 - 0s - loss: 0.3485 - accuracy: 0.8280\n",
      "Epoch 41/150\n",
      "5243/5243 - 0s - loss: 0.3465 - accuracy: 0.8314\n",
      "Epoch 42/150\n",
      "5243/5243 - 0s - loss: 0.3447 - accuracy: 0.8287\n",
      "Epoch 43/150\n",
      "5243/5243 - 0s - loss: 0.3464 - accuracy: 0.8295\n",
      "Epoch 44/150\n",
      "5243/5243 - 0s - loss: 0.3453 - accuracy: 0.8282\n",
      "Epoch 45/150\n",
      "5243/5243 - 0s - loss: 0.3410 - accuracy: 0.8350\n",
      "Epoch 46/150\n",
      "5243/5243 - 0s - loss: 0.3425 - accuracy: 0.8308\n",
      "Epoch 47/150\n",
      "5243/5243 - 0s - loss: 0.3412 - accuracy: 0.8264\n",
      "Epoch 48/150\n",
      "5243/5243 - 0s - loss: 0.3359 - accuracy: 0.8396\n",
      "Epoch 49/150\n",
      "5243/5243 - 0s - loss: 0.3341 - accuracy: 0.8371\n",
      "Epoch 50/150\n",
      "5243/5243 - 0s - loss: 0.3325 - accuracy: 0.8415\n",
      "Epoch 51/150\n",
      "5243/5243 - 0s - loss: 0.3327 - accuracy: 0.8446\n",
      "Epoch 52/150\n",
      "5243/5243 - 0s - loss: 0.3269 - accuracy: 0.8488\n",
      "Epoch 53/150\n",
      "5243/5243 - 0s - loss: 0.3251 - accuracy: 0.8474\n",
      "Epoch 54/150\n",
      "5243/5243 - 0s - loss: 0.3270 - accuracy: 0.8453\n",
      "Epoch 55/150\n",
      "5243/5243 - 0s - loss: 0.3239 - accuracy: 0.8507\n",
      "Epoch 56/150\n",
      "5243/5243 - 0s - loss: 0.3226 - accuracy: 0.8505\n",
      "Epoch 57/150\n",
      "5243/5243 - 0s - loss: 0.3188 - accuracy: 0.8575\n",
      "Epoch 58/150\n",
      "5243/5243 - 0s - loss: 0.3187 - accuracy: 0.8495\n",
      "Epoch 59/150\n",
      "5243/5243 - 0s - loss: 0.3136 - accuracy: 0.8545\n",
      "Epoch 60/150\n",
      "5243/5243 - 0s - loss: 0.3126 - accuracy: 0.8562\n",
      "Epoch 61/150\n",
      "5243/5243 - 0s - loss: 0.3107 - accuracy: 0.8602\n",
      "Epoch 62/150\n",
      "5243/5243 - 0s - loss: 0.3096 - accuracy: 0.8591\n",
      "Epoch 63/150\n",
      "5243/5243 - 0s - loss: 0.3109 - accuracy: 0.8625\n",
      "Epoch 64/150\n",
      "5243/5243 - 0s - loss: 0.3046 - accuracy: 0.8655\n",
      "Epoch 65/150\n",
      "5243/5243 - 0s - loss: 0.3095 - accuracy: 0.8598\n",
      "Epoch 66/150\n",
      "5243/5243 - 0s - loss: 0.3057 - accuracy: 0.8638\n",
      "Epoch 67/150\n",
      "5243/5243 - 0s - loss: 0.3050 - accuracy: 0.8644\n",
      "Epoch 68/150\n",
      "5243/5243 - 0s - loss: 0.3029 - accuracy: 0.8665\n",
      "Epoch 69/150\n",
      "5243/5243 - 0s - loss: 0.3023 - accuracy: 0.8648\n",
      "Epoch 70/150\n",
      "5243/5243 - 0s - loss: 0.3027 - accuracy: 0.8659\n",
      "Epoch 71/150\n",
      "5243/5243 - 0s - loss: 0.2941 - accuracy: 0.8707\n",
      "Epoch 72/150\n",
      "5243/5243 - 0s - loss: 0.2973 - accuracy: 0.8657\n",
      "Epoch 73/150\n",
      "5243/5243 - 0s - loss: 0.2977 - accuracy: 0.8652\n",
      "Epoch 74/150\n",
      "5243/5243 - 0s - loss: 0.2969 - accuracy: 0.8678\n",
      "Epoch 75/150\n",
      "5243/5243 - 0s - loss: 0.2954 - accuracy: 0.8652\n",
      "Epoch 76/150\n",
      "5243/5243 - 0s - loss: 0.2948 - accuracy: 0.8720\n",
      "Epoch 77/150\n",
      "5243/5243 - 0s - loss: 0.2927 - accuracy: 0.8705\n",
      "Epoch 78/150\n",
      "5243/5243 - 0s - loss: 0.2996 - accuracy: 0.8629\n",
      "Epoch 79/150\n",
      "5243/5243 - 0s - loss: 0.2935 - accuracy: 0.8671\n",
      "Epoch 80/150\n",
      "5243/5243 - 0s - loss: 0.2908 - accuracy: 0.8705\n",
      "Epoch 81/150\n",
      "5243/5243 - 0s - loss: 0.2946 - accuracy: 0.8684\n",
      "Epoch 82/150\n",
      "5243/5243 - 0s - loss: 0.2878 - accuracy: 0.8732\n",
      "Epoch 83/150\n",
      "5243/5243 - 0s - loss: 0.2912 - accuracy: 0.8713\n",
      "Epoch 84/150\n",
      "5243/5243 - 0s - loss: 0.2883 - accuracy: 0.8728\n",
      "Epoch 85/150\n",
      "5243/5243 - 0s - loss: 0.2911 - accuracy: 0.8724\n",
      "Epoch 86/150\n",
      "5243/5243 - 0s - loss: 0.2974 - accuracy: 0.8653\n",
      "Epoch 87/150\n",
      "5243/5243 - 0s - loss: 0.2869 - accuracy: 0.8745\n",
      "Epoch 88/150\n",
      "5243/5243 - 0s - loss: 0.2890 - accuracy: 0.8722\n",
      "Epoch 89/150\n",
      "5243/5243 - 0s - loss: 0.2873 - accuracy: 0.8745\n",
      "Epoch 90/150\n",
      "5243/5243 - 0s - loss: 0.2862 - accuracy: 0.8722\n",
      "Epoch 91/150\n",
      "5243/5243 - 0s - loss: 0.2887 - accuracy: 0.8701\n",
      "Epoch 92/150\n",
      "5243/5243 - 0s - loss: 0.2870 - accuracy: 0.8701\n",
      "Epoch 93/150\n",
      "5243/5243 - 0s - loss: 0.2872 - accuracy: 0.8692\n",
      "Epoch 94/150\n",
      "5243/5243 - 0s - loss: 0.2854 - accuracy: 0.8713\n",
      "Epoch 95/150\n",
      "5243/5243 - 0s - loss: 0.2896 - accuracy: 0.8667\n",
      "Epoch 96/150\n",
      "5243/5243 - 0s - loss: 0.2907 - accuracy: 0.8671\n",
      "Epoch 97/150\n",
      "5243/5243 - 0s - loss: 0.2823 - accuracy: 0.8762\n",
      "Epoch 98/150\n",
      "5243/5243 - 0s - loss: 0.2842 - accuracy: 0.8779\n",
      "Epoch 99/150\n",
      "5243/5243 - 0s - loss: 0.2848 - accuracy: 0.8728\n",
      "Epoch 100/150\n",
      "5243/5243 - 0s - loss: 0.2812 - accuracy: 0.8749\n",
      "Epoch 101/150\n",
      "5243/5243 - 0s - loss: 0.2846 - accuracy: 0.8693\n",
      "Epoch 102/150\n",
      "5243/5243 - 0s - loss: 0.2876 - accuracy: 0.8693\n",
      "Epoch 103/150\n",
      "5243/5243 - 0s - loss: 0.2840 - accuracy: 0.8747\n",
      "Epoch 104/150\n",
      "5243/5243 - 0s - loss: 0.2860 - accuracy: 0.8739\n",
      "Epoch 105/150\n",
      "5243/5243 - 0s - loss: 0.2819 - accuracy: 0.8743\n",
      "Epoch 106/150\n",
      "5243/5243 - 0s - loss: 0.2821 - accuracy: 0.8747\n",
      "Epoch 107/150\n",
      "5243/5243 - 0s - loss: 0.2815 - accuracy: 0.8791\n",
      "Epoch 108/150\n",
      "5243/5243 - 0s - loss: 0.2828 - accuracy: 0.8745\n",
      "Epoch 109/150\n",
      "5243/5243 - 0s - loss: 0.2799 - accuracy: 0.8779\n",
      "Epoch 110/150\n",
      "5243/5243 - 0s - loss: 0.2797 - accuracy: 0.8770\n",
      "Epoch 111/150\n",
      "5243/5243 - 0s - loss: 0.2817 - accuracy: 0.8776\n",
      "Epoch 112/150\n",
      "5243/5243 - 0s - loss: 0.2813 - accuracy: 0.8774\n",
      "Epoch 113/150\n",
      "5243/5243 - 0s - loss: 0.2821 - accuracy: 0.8764\n",
      "Epoch 114/150\n",
      "5243/5243 - 0s - loss: 0.2834 - accuracy: 0.8734\n",
      "Epoch 115/150\n",
      "5243/5243 - 0s - loss: 0.2797 - accuracy: 0.8795\n",
      "Epoch 116/150\n",
      "5243/5243 - 0s - loss: 0.2773 - accuracy: 0.8814\n",
      "Epoch 117/150\n",
      "5243/5243 - 0s - loss: 0.2914 - accuracy: 0.8674\n",
      "Epoch 118/150\n",
      "5243/5243 - 0s - loss: 0.2809 - accuracy: 0.8777\n",
      "Epoch 119/150\n",
      "5243/5243 - 0s - loss: 0.2806 - accuracy: 0.8766\n",
      "Epoch 120/150\n",
      "5243/5243 - 0s - loss: 0.2876 - accuracy: 0.8739\n",
      "Epoch 121/150\n",
      "5243/5243 - 0s - loss: 0.2771 - accuracy: 0.8785\n",
      "Epoch 122/150\n",
      "5243/5243 - 0s - loss: 0.2780 - accuracy: 0.8758\n",
      "Epoch 123/150\n",
      "5243/5243 - 0s - loss: 0.2794 - accuracy: 0.8766\n",
      "Epoch 124/150\n",
      "5243/5243 - 0s - loss: 0.2835 - accuracy: 0.8728\n",
      "Epoch 125/150\n",
      "5243/5243 - 0s - loss: 0.2757 - accuracy: 0.8766\n",
      "Epoch 126/150\n",
      "5243/5243 - 0s - loss: 0.2754 - accuracy: 0.8783\n",
      "Epoch 127/150\n",
      "5243/5243 - 0s - loss: 0.2772 - accuracy: 0.8755\n",
      "Epoch 128/150\n",
      "5243/5243 - 0s - loss: 0.2798 - accuracy: 0.8774\n",
      "Epoch 129/150\n",
      "5243/5243 - 0s - loss: 0.2762 - accuracy: 0.8795\n",
      "Epoch 130/150\n",
      "5243/5243 - 0s - loss: 0.2759 - accuracy: 0.8779\n",
      "Epoch 131/150\n",
      "5243/5243 - 0s - loss: 0.2763 - accuracy: 0.8781\n",
      "Epoch 132/150\n",
      "5243/5243 - 0s - loss: 0.2762 - accuracy: 0.8760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/150\n",
      "5243/5243 - 0s - loss: 0.2796 - accuracy: 0.8760\n",
      "Epoch 134/150\n",
      "5243/5243 - 0s - loss: 0.2748 - accuracy: 0.8774\n",
      "Epoch 135/150\n",
      "5243/5243 - 0s - loss: 0.2820 - accuracy: 0.8770\n",
      "Epoch 136/150\n",
      "5243/5243 - 0s - loss: 0.2790 - accuracy: 0.8795\n",
      "Epoch 137/150\n",
      "5243/5243 - 0s - loss: 0.2799 - accuracy: 0.8755\n",
      "Epoch 138/150\n",
      "5243/5243 - 0s - loss: 0.2738 - accuracy: 0.8810\n",
      "Epoch 139/150\n",
      "5243/5243 - 0s - loss: 0.2765 - accuracy: 0.8747\n",
      "Epoch 140/150\n",
      "5243/5243 - 0s - loss: 0.2777 - accuracy: 0.8796\n",
      "Epoch 141/150\n",
      "5243/5243 - 0s - loss: 0.2759 - accuracy: 0.8789\n",
      "Epoch 142/150\n",
      "5243/5243 - 0s - loss: 0.2765 - accuracy: 0.8768\n",
      "Epoch 143/150\n",
      "5243/5243 - 0s - loss: 0.2799 - accuracy: 0.8726\n",
      "Epoch 144/150\n",
      "5243/5243 - 0s - loss: 0.2750 - accuracy: 0.8795\n",
      "Epoch 145/150\n",
      "5243/5243 - 0s - loss: 0.2776 - accuracy: 0.8777\n",
      "Epoch 146/150\n",
      "5243/5243 - 0s - loss: 0.2737 - accuracy: 0.8795\n",
      "Epoch 147/150\n",
      "5243/5243 - 0s - loss: 0.2753 - accuracy: 0.8800\n",
      "Epoch 148/150\n",
      "5243/5243 - 0s - loss: 0.2721 - accuracy: 0.8802\n",
      "Epoch 149/150\n",
      "5243/5243 - 0s - loss: 0.2794 - accuracy: 0.8743\n",
      "Epoch 150/150\n",
      "5243/5243 - 0s - loss: 0.2727 - accuracy: 0.8814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2969a228be0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=150,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1748/1748 - 0s - loss: 0.3042 - accuracy: 0.8862\n",
      "Normal Neural Network - Loss: 0.3042429618759068, Accuracy: 0.8861556053161621\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Use `GridSearchCV` to tune the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the GridSearchCV model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC \n",
    "model3 = SVC(kernel='linear')\n",
    "model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with GridSearch\n",
    "param_grid = {'C': [1, 10, 50],\n",
    "              'gamma': [0.0001, 0.001, 0.01]}\n",
    "grid = GridSearchCV(model3, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0001, score=0.834, total=   0.1s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1, gamma=0.0001, score=0.819, total=   0.1s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0001, score=0.820, total=   0.1s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0001, score=0.825, total=   0.1s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1, gamma=0.0001, score=0.815, total=   0.1s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.834, total=   0.1s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.819, total=   0.1s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.820, total=   0.1s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.825, total=   0.1s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.815, total=   0.1s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ..................... C=1, gamma=0.01, score=0.834, total=   0.1s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ..................... C=1, gamma=0.01, score=0.819, total=   0.1s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ..................... C=1, gamma=0.01, score=0.820, total=   0.1s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ..................... C=1, gamma=0.01, score=0.825, total=   0.1s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ..................... C=1, gamma=0.01, score=0.815, total=   0.1s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.846, total=   0.1s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.830, total=   0.1s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.827, total=   0.1s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.840, total=   0.1s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.824, total=   0.1s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.846, total=   0.1s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.830, total=   0.1s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.827, total=   0.1s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.840, total=   0.1s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.824, total=   0.1s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] .................... C=10, gamma=0.01, score=0.846, total=   0.1s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] .................... C=10, gamma=0.01, score=0.830, total=   0.1s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] .................... C=10, gamma=0.01, score=0.827, total=   0.1s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] .................... C=10, gamma=0.01, score=0.840, total=   0.1s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] .................... C=10, gamma=0.01, score=0.824, total=   0.1s\n",
      "[CV] C=50, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0001, score=0.859, total=   0.1s\n",
      "[CV] C=50, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0001, score=0.838, total=   0.1s\n",
      "[CV] C=50, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0001, score=0.838, total=   0.1s\n",
      "[CV] C=50, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0001, score=0.868, total=   0.1s\n",
      "[CV] C=50, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0001, score=0.847, total=   0.1s\n",
      "[CV] C=50, gamma=0.001 ...............................................\n",
      "[CV] ................... C=50, gamma=0.001, score=0.859, total=   0.1s\n",
      "[CV] C=50, gamma=0.001 ...............................................\n",
      "[CV] ................... C=50, gamma=0.001, score=0.838, total=   0.1s\n",
      "[CV] C=50, gamma=0.001 ...............................................\n",
      "[CV] ................... C=50, gamma=0.001, score=0.838, total=   0.1s\n",
      "[CV] C=50, gamma=0.001 ...............................................\n",
      "[CV] ................... C=50, gamma=0.001, score=0.868, total=   0.1s\n",
      "[CV] C=50, gamma=0.001 ...............................................\n",
      "[CV] ................... C=50, gamma=0.001, score=0.847, total=   0.1s\n",
      "[CV] C=50, gamma=0.01 ................................................\n",
      "[CV] .................... C=50, gamma=0.01, score=0.859, total=   0.1s\n",
      "[CV] C=50, gamma=0.01 ................................................\n",
      "[CV] .................... C=50, gamma=0.01, score=0.838, total=   0.1s\n",
      "[CV] C=50, gamma=0.01 ................................................\n",
      "[CV] .................... C=50, gamma=0.01, score=0.838, total=   0.1s\n",
      "[CV] C=50, gamma=0.01 ................................................\n",
      "[CV] .................... C=50, gamma=0.01, score=0.868, total=   0.1s\n",
      "[CV] C=50, gamma=0.01 ................................................\n",
      "[CV] .................... C=50, gamma=0.01, score=0.847, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:    5.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='linear', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': [1, 10, 50], 'gamma': [0.0001, 0.001, 0.01]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 50, 'gamma': 0.0001}\n",
      "0.8500887795719659\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CANDIDATE       0.82      0.58      0.68       422\n",
      "FALSE POSITIVE       0.69      0.85      0.76       450\n",
      "FALSE NEGATIVE       0.98      1.00      0.99       876\n",
      "\n",
      "      accuracy                           0.86      1748\n",
      "     macro avg       0.83      0.81      0.81      1748\n",
      "  weighted avg       0.86      0.86      0.85      1748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = grid.predict(X_test_scaled)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions,\n",
    "                            target_names=[\"CANDIDATE\", \"FALSE POSITIVE\", \"FALSE NEGATIVE\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, Train/Test Score: 1.000/0.838\n",
      "k: 3, Train/Test Score: 0.911/0.856\n",
      "k: 5, Train/Test Score: 0.892/0.867\n",
      "k: 7, Train/Test Score: 0.883/0.868\n",
      "k: 9, Train/Test Score: 0.880/0.867\n",
      "k: 11, Train/Test Score: 0.874/0.870\n",
      "k: 13, Train/Test Score: 0.874/0.874\n",
      "k: 15, Train/Test Score: 0.873/0.874\n",
      "k: 17, Train/Test Score: 0.871/0.871\n",
      "k: 19, Train/Test Score: 0.872/0.872\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 20, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    train_score = knn.score(X_train_scaled, y_train)\n",
    "    test_score = knn.score(X_test_scaled, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    \n",
    "    \n",
    "plt.plot(range(1, 20, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 20, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=9 Test Acc: 0.874\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=13)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "print('k=9 Test Acc: %.3f' % knn.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your model by updating \"your_name\" with your name\n",
    "# and \"your_model\" with your model variable\n",
    "# be sure to turn this in to BCS\n",
    "# if joblib fails to import, try running the command to install in terminal/git-bash\n",
    "import joblib\n",
    "filename = 'your_name.sav'\n",
    "joblib.dump(your_model, filename)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
